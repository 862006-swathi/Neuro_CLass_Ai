<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>NeuroClass AI | Smart Classroom</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@600&family=Inter&display=swap" rel="stylesheet">
<script defer src="https://unpkg.com/face-api.js@0.22.2"></script>

<style>
body{margin:0;font-family:Inter;background:#0b0f1a;color:#fff}
header{padding:16px 6%;background:#000a;display:flex;justify-content:space-between}
header h2{font-family:Orbitron}
header span{color:#6a5acd}

main{
  display:grid;
  grid-template-columns:1fr 360px;
  gap:18px;
  padding:30px 6%;
}

.video-box{
  height:420px;
  background:#000;
  border-radius:18px;
  position:relative;
  overflow:hidden;
}

video{width:100%;height:100%;object-fit:cover}

#emotionGif{
  position:absolute;
  bottom:14px;
  right:14px;
  width:120px;
  border-radius:12px;
}

.controls{
  position:absolute;
  bottom:14px;
  left:50%;
  transform:translateX(-50%);
  display:flex;
  gap:14px;
}

.control-btn{
  width:46px;height:46px;border-radius:50%;
  border:none;font-size:20px;
  cursor:pointer;
  background:#1c2238;color:#fff;
}

.control-btn.active{background:#6a5acd}
.control-btn.exit{background:#e53935}

.emoji-bar{
  display:flex;
  justify-content:center;
  gap:24px;
  margin-top:14px;
}

.emoji{font-size:34px;opacity:.3;transition:.25s}
.emoji.active{opacity:1;transform:scale(1.3)}

.transcript{
  background:#060814;
  border-radius:18px;
  padding:16px;
  display:flex;
  flex-direction:column;
}

.transcript h3{
  font-family:Orbitron;
  font-size:16px;
  margin-bottom:10px;
  opacity:.85;
}

#transcriptText{
  flex:1;
  overflow-y:auto;
  font-size:14px;
  line-height:1.6;
}

.line{margin-bottom:8px;opacity:.9}
</style>
</head>

<body>

<header>
  <h2><span>Neuro</span>Class AI</h2>
  <div id="emotion">Emotion: LOADING</div>
</header>

<main>

<div>
  <div class="video-box">
    <video id="video" autoplay muted playsinline></video>
    <img id="emotionGif">

    <div class="controls">
      <button id="camBtn" class="control-btn active">ğŸ¥</button>
      <button id="micBtn" class="control-btn">ğŸ¤</button>
      <button class="control-btn exit" onclick="location.href='/'">ğŸšª</button>
    </div>
  </div>

  <div class="emoji-bar">
    <div class="emoji" id="neutral">ğŸ˜</div>
    <div class="emoji" id="bored">ğŸ˜´</div>
    <div class="emoji" id="confused">ğŸ¤”</div>
    <div class="emoji" id="doubt">ğŸ§</div>
    <div class="emoji" id="interested">ğŸ˜„</div>
  </div>
</div>

<div class="transcript">
  <h3>Live Transcription</h3>
  <div id="transcriptText"></div>
</div>

</main>

<script>
/* ================= MEDIA ================= */
const video = document.getElementById("video");
let mediaStream, videoTrack, audioTrack;

async function startMedia(){
  mediaStream = await navigator.mediaDevices.getUserMedia({ video:true, audio:true });
  video.srcObject = mediaStream;
  videoTrack = mediaStream.getVideoTracks()[0];
  audioTrack = mediaStream.getAudioTracks()[0];
}
startMedia();

/* ================= CONTROLS ================= */
camBtn.onclick = () => {
  videoTrack.enabled = !videoTrack.enabled;
  camBtn.classList.toggle("active", videoTrack.enabled);
};

let ws=null, audioCtx=null, processor=null, source=null, recording=false;

micBtn.onclick = async () => {
  recording = !recording;
  micBtn.classList.toggle("active", recording);
  if(recording) await startTranscription();
  else stopTranscription();
};

/* ================= TRANSCRIPTION ================= */
const transcriptBox=document.getElementById("transcriptText");

function addLine(text){
  const div=document.createElement("div");
  div.className="line";
  div.textContent=text;
  transcriptBox.appendChild(div);
  transcriptBox.scrollTop=transcriptBox.scrollHeight;
}

async function startTranscription(){
  ws=new WebSocket(`${location.protocol==="https:"?"wss":"ws"}://${location.host}/ws/transcribe`);

  ws.onmessage=e=>{
    const d=JSON.parse(e.data);
    if(d.text) addLine(d.text);
  };

  audioCtx=new AudioContext({sampleRate:16000});
  source=audioCtx.createMediaStreamSource(mediaStream);
  processor=audioCtx.createScriptProcessor(4096,1,1);

  source.connect(processor);
  processor.connect(audioCtx.destination);

  processor.onaudioprocess=e=>{
    if(!recording || ws.readyState!==1) return;
    const i=e.inputBuffer.getChannelData(0);
    const pcm=new Int16Array(i.length);
    for(let x=0;x<i.length;x++){
      pcm[x]=Math.max(-1,Math.min(1,i[x]))*32767;
    }
    ws.send(pcm.buffer);
  };
}

function stopTranscription(){
  if(processor) processor.disconnect();
  if(source) source.disconnect();
  if(audioCtx) audioCtx.close();
  if(ws) ws.close();
}

/* ================= EMOTION AI ================= */
const emotionText=document.getElementById("emotion");
const gif=document.getElementById("emotionGif");
const emojis={neutral, bored, confused, doubt, interested};

const gifs={
  neutral:"https://media.giphy.com/media/3o7btPCcdNniyf0ArS/giphy.gif",
  bored:"https://media.giphy.com/media/3o6ZsV7fGJZQ0cS2k0/giphy.gif",
  confused:"https://media.giphy.com/media/l0MYt5jPR6QX5pnqM/giphy.gif",
  doubt:"https://media.giphy.com/media/l0HlRnAWXxn0MhKLK/giphy.gif",
  interested:"https://media.giphy.com/media/26gsspfbt1HfVQ9va/giphy.gif"
};

function activate(state){
  Object.values(emojis).forEach(e=>e.classList.remove("active"));
  emojis[state].classList.add("active");
  gif.src=gifs[state];
  emotionText.textContent="Emotion: "+state.toUpperCase();
}

function classify(e){
  if(e.sad>0.45) return "bored";
  if(e.fearful>0.35) return "doubt";
  if(e.surprised>0.35 && e.neutral>0.3) return "confused";
  if(e.happy>0.4 || e.surprised>0.5) return "interested";
  return "neutral";
}

async function loadAI(){
  await faceapi.nets.tinyFaceDetector.loadFromUri("/models");
  await faceapi.nets.faceExpressionNet.loadFromUri("/models");
}

async function detect(){
  if(video.readyState!==4) return;
  const r=await faceapi
    .detectSingleFace(video,new faceapi.TinyFaceDetectorOptions())
    .withFaceExpressions();
  if(r) activate(classify(r.expressions));
}

/* INIT */
(async()=>{
  await loadAI();
  emotionText.textContent="Emotion: ONLINE";
  setInterval(detect,1000);
})();
</script>

</body>
</html>